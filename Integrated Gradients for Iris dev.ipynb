{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as k\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--## import and format data ##--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv(\"C:\\\\Users\\\\nickolas.oddo\\\\Desktop\\\\Iris Dataset Integrated Gradients\\\\iris.csv\")\n",
    "iris_featurenames=list(iris.columns[:-1])\n",
    "class_lib={0:\"Iris-setosa\", 1:\"Iris-versicolor\",2:\"Iris-virginica\" }\n",
    "feature_lib={i:item for i,item in enumerate(iris_featurenames)}\n",
    "X,Y=np.array(iris.iloc[:,:4]),np.array(iris.iloc[:,4])\n",
    "Y=k.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--### create model and load weights ###--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_layer (InputLayer)     [(None, 4)]               0         \n_________________________________________________________________\ndense_layer (Dense)          (None, 10)                50        \n_________________________________________________________________\noutput (Dense)               (None, 3)                 33        \n=================================================================\nTotal params: 83\nTrainable params: 83\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "folder_path='C:\\\\Users\\\\nickolas.oddo\\\\Desktop\\\\Iris Dataset Integrated Gradients\\\\model weights\\\\irismod'\n",
    "model=k.models.load_model(folder_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--### define functions for integrated gradients ###--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputshape=X[np.newaxis,0].shape\n",
    "outputshape=Y[np.newaxis,0].shape\n",
    "\n",
    "#Using random baseline- can be used for expected gradients.\n",
    "def baseline(input,sd=.25):\n",
    "    noisy_input=input+np.random.normal(scale=sd,size=inputshape)\n",
    "    noisy_input=noisy_input.reshape(inputshape)\n",
    "    noisy_input=tf.convert_to_tensor(noisy_input,dtype='float32')\n",
    "    return(noisy_input)\n",
    "\n",
    "def convert_to_tensor(X,Y,input_index=0):\n",
    "    x=np.array(X[input_index]).reshape(inputshape)\n",
    "    y=np.array(Y[input_index,:]).reshape(outputshape)\n",
    "#     b=np.array(baseline(x)).reshape((1,4))\n",
    "    x=tf.convert_to_tensor(x, dtype='float32')\n",
    "    y=tf.convert_to_tensor(y, dtype='float32')\n",
    "#     b=tf.convert_to_tensor(b, dtype='float64')\n",
    "    return(x,y)\n",
    "\n",
    "#m_steps indicates the step size of the numerical integral to be calculated\n",
    "m_steps=1000\n",
    "alphas=tf.linspace(start=0.0,stop=1.0,num=m_steps+1)\n",
    "\n",
    "def interpolate_features(baseline,features,alphas):\n",
    "    alphas_x = alphas[:, tf.newaxis]\n",
    "    alphas_x= tf.convert_to_tensor(alphas_x,dtype='float32')\n",
    "    baseline_x =baseline\n",
    "    # input_x = tf.expand_dims(features, axis=0)\n",
    "    delta = features - baseline_x\n",
    "    interp_feat = baseline_x +  alphas_x * delta\n",
    "    return interp_feat\n",
    "\n",
    "def compute_gradients(x,class_idx):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        yhat=model(x)[:,class_idx]\n",
    "#         loss=tf.losses.categorical_crossentropy(y,yhat)\n",
    "    grads=tape.gradient(yhat,x)\n",
    "    return(grads)\n",
    "\n",
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(gradients, axis=0)\n",
    "    return integrated_gradients\n",
    "\n",
    "def integrated_gradients(X,Y,sample_idx,class_idx):\n",
    "    x,y=convert_to_tensor(X,Y,sample_idx)\n",
    "    b=baseline(X,sample_idx)\n",
    "    interp_feat=interpolate_features(b,x,alphas)\n",
    "    interp_grads=compute_gradients(interp_feat,class_idx)\n",
    "    integ_gradients=(x-b)*integral_approximation(interp_grads)\n",
    "    return(integ_gradients)\n",
    "\n",
    "def calculate_integrated_gradients(input_index,baseline_vector,class_idx=0):\n",
    "    x,y=convert_to_tensor(X,Y,input_index)\n",
    "    b=baseline_vector\n",
    "    interp_feat=interpolate_features(b,x,alphas)\n",
    "    interp_grads=compute_gradients(interp_feat,class_idx)\n",
    "    integ_gradients=(x-b)*integral_approximation(interp_grads)\n",
    "    return(integ_gradients)\n",
    "\n",
    "def repeated_ig(input_index,class_index,num_reps=10):\n",
    "    a=calculate_integrated_gradients(input_index=input_index,class_idx=class_index).numpy()\n",
    "    a=np.array([calculate_integrated_gradients(input_index=input_idx,class_idx=0).numpy() for i in range(1,num_reps)])\n",
    "    return(np.mean(b,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--### calculate integrated gradients ###--\n",
    "integrated_gradients function:\n",
    "X=features input\n",
    "Y=target class\n",
    "sample_idx= which observation to calculate on (0 to 149 observations) \n",
    "class_idx= which classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-3.9875507e-04,  1.1775763e+00,  1.2191293e+00], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "input_idx=1 #which example to look at (0 through 150)\n",
    "\n",
    "x,y=convert_to_tensor(X,Y,input_idx)\n",
    "class_idx=np.argmax(model(x))\n",
    "b=baseline(np.mean(X,axis=0)) #use mean of data with N(0,.25) noise\n",
    "class_idx=np.argmax(model.predict(x))\n",
    "\n",
    "ig=calculate_integrated_gradients(input_idx,b,class_idx)\n",
    "tf.reduce_sum(ig).numpy()-(model(x)[class_idx]-model(b)[class_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--### Convergence check: \n",
    "letting $\\phi_i(x)$ be the integrated gradients feature attribution givien to feature $i$:\n",
    "\n",
    "$\\sum_{i=1}^k{\\phi_i(x)}=F(x)-F(x{'})$ \n",
    "\n",
    "then\n",
    "$\\sum_{i=1}^k{\\phi_i(x)}-[F(x)-F(x^\\prime)] <\\epsilon$  for some sufficiently small epsilon\n",
    "\n",
    "in this case, the softmax output predicts three class probabilities.\n",
    "A different feature attribution will be given to each class prediction probability.\n",
    "showing the \n",
    "###--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.24044162"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "\n",
    "f_x=model.predict(x)[0][class_idx]\n",
    "f_b=model.predict(b)[0][class_idx]\n",
    "ig=calculate_integrated_gradients(input_idx,class_idx)\n",
    "# ig= repeated_ig(input_idx,class_idx,1)\n",
    "\n",
    "conv_check=tf.reduce_sum(ig) - (f_x-f_b)\n",
    "conv_check.numpy() #This should be close to zero\n",
    "# calculate_integrated_gradients(input_idx,class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eccc0a27c0>"
      ],
      "text/html": "<style  type=\"text/css\" >\n#T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col0{\n            background-color:  #00441b;\n            color:  #f1f1f1;\n        }#T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col1{\n            background-color:  #a5db9f;\n            color:  #000000;\n        }#T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col2{\n            background-color:  #f7fcf5;\n            color:  #000000;\n        }#T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col3{\n            background-color:  #ccebc6;\n            color:  #000000;\n        }</style><table id=\"T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dc\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >sepal_l</th>        <th class=\"col_heading level0 col1\" >sepal_w</th>        <th class=\"col_heading level0 col2\" >petal_l</th>        <th class=\"col_heading level0 col3\" >petal_w</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dclevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col0\" class=\"data row0 col0\" >0.854214</td>\n                        <td id=\"T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col1\" class=\"data row0 col1\" >0.096945</td>\n                        <td id=\"T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col2\" class=\"data row0 col2\" >-0.332911</td>\n                        <td id=\"T_5d6f6cab_d5d2_11eb_b04d_d89ef32b43dcrow0_col3\" class=\"data row0 col3\" >-0.059522</td>\n            </tr>\n    </tbody></table>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "\n",
    "a=ig\n",
    "df=pd.DataFrame(a.numpy(), columns=iris_featurenames)\n",
    "df.style.background_gradient(cmap='Greens', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.00019928,  0.00041836,  0.00290322,  0.01082668]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "source": [
    "repeated_ig(input_idx,class_idx,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.00079678, -0.00023994,  0.00558045,  0.00111783]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "np.mean(b,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([[-0.04914541 -0.00057522  0.00023594  0.06285616]], shape=(1, 4), dtype=float32)\npredicted class:  Iris-setosa\ntrue class:  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "input_idx=2\n",
    "print(calculate_integrated_gradients(input_index=input_idx,class_idx=0))\n",
    "print(\"predicted class: \",class_lib[np.argmax(model.predict(X[np.newaxis,input_idx]))])\n",
    "print(\"true class: \", class_lib[np.argmax(Y[input_idx])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.04584731, 0.00743598, 0.05995739, 0.03946051]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "sum(model.predict(x))\n",
    "integ_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.04584731, 0.00743598, 0.05995739, 0.03946051]], dtype=float32)>>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "integ_gradients.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 0], dtype=int64)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}